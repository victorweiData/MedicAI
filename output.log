[I 2025-06-20 21:08:42,753] A new study created in memory with name: no-name-c90ef51c-f8ee-4a72-8a4b-9fedd3ef1dc3
Using device: cuda

  0%|          | 0/20 [00:00<?, ?it/s]
── Trial 0 ──
{
  "lr": 0.008244162602397142,
  "batch_size": 64,
  "optimizer": "sgd",
  "weight_decay": 0.002712782161696706,
  "milestones": [
    30,
    38
  ],
  "gamma": 0.2740513446648188,
  "patience": 12,
  "val_freq": 6
}
→ Using 7 GPUs via DataParallel
Epoch  6 | train=0.1923 | val_loss=0.3511 | val_acc=0.8926
  ↳ improved
Epoch 12 | train=0.1682 | val_loss=0.1977 | val_acc=0.9407
  ↳ improved
Epoch 18 | train=0.1346 | val_loss=0.3469 | val_acc=0.8894
  ↳ no‑improve (1/12)

                                      

  0%|          | 0/20 [07:05<?, ?it/s]
Best trial: 0. Best value: 0.955128:   0%|          | 0/20 [07:05<?, ?it/s]
Best trial: 0. Best value: 0.955128:   5%|▌         | 1/20 [07:05<2:14:41, 425.36s/it][I 2025-06-20 21:15:48,112] Trial 0 finished with value: 0.9551282051282052 and parameters: {'lr': 0.008244162602397142, 'batch_size': 64, 'optimizer': 'sgd', 'weight_decay': 0.002712782161696706, 'milestone1': 30, 'milestone2': 38, 'gamma': 0.2740513446648188, 'patience': 12, 'validation_freq': 6}. Best is trial 0 with value: 0.9551282051282052.

── Trial 1 ──
{
  "lr": 0.00028817932854540036,
  "batch_size": 16,
  "optimizer": "adam",
  "weight_decay": 2.998457667692623e-05,
  "milestones": [
    23,
    45
  ],
  "gamma": 0.23066152578241234,
  "patience": 9,
  "val_freq": 4
}
→ Using 7 GPUs via DataParallel
Epoch  4 | train=0.2220 | val_loss=0.3895 | val_acc=0.8526
  ↳ improved
Epoch  8 | train=0.1731 | val_loss=0.4685 | val_acc=0.8141
  ↳ no‑improve (1/9)
Epoch 12 | train=0.1665 | val_loss=0.1587 | val_acc=0.9407
  ↳ improved
Epoch 16 | train=0.1627 | val_loss=0.1937 | val_acc=0.9327
  ↳ no‑improve (1/9)

                                                                                      

Best trial: 0. Best value: 0.955128:   5%|▌         | 1/20 [21:13<2:14:41, 425.36s/it]
Best trial: 0. Best value: 0.955128:   5%|▌         | 1/20 [21:13<2:14:41, 425.36s/it]
Best trial: 0. Best value: 0.955128:  10%|█         | 2/20 [21:13<3:22:08, 673.79s/it]Epoch 20 | train=0.1585 | val_loss=0.1984 | val_acc=0.9375
  ↳ no‑improve (2/9)
[I 2025-06-20 21:29:55,808] Trial 1 finished with value: 0.9407051282051282 and parameters: {'lr': 0.00028817932854540036, 'batch_size': 16, 'optimizer': 'adam', 'weight_decay': 2.998457667692623e-05, 'milestone1': 23, 'milestone2': 45, 'gamma': 0.23066152578241234, 'patience': 9, 'validation_freq': 4}. Best is trial 0 with value: 0.9551282051282052.

── Trial 2 ──
{
  "lr": 0.00023687542089798446,
  "batch_size": 16,
  "optimizer": "sgd",
  "weight_decay": 2.613653475954567e-06,
  "milestones": [
    27,
    38
  ],
  "gamma": 0.2981291422222043,
  "patience": 10,
  "val_freq": 5
}
→ Using 7 GPUs via DataParallel
Epoch  5 | train=0.3339 | val_loss=0.2635 | val_acc=0.9119
  ↳ improved
Epoch 10 | train=0.3096 | val_loss=0.1984 | val_acc=0.9375
  ↳ improved
Epoch 15 | train=0.2995 | val_loss=0.1965 | val_acc=0.9487
  ↳ improved

                                                                                      

Best trial: 0. Best value: 0.955128:  10%|█         | 2/20 [36:12<3:22:08, 673.79s/it]
Best trial: 0. Best value: 0.955128:  10%|█         | 2/20 [36:12<3:22:08, 673.79s/it]
Best trial: 0. Best value: 0.955128:  15%|█▌        | 3/20 [36:12<3:40:08, 776.99s/it]Epoch 20 | train=0.2702 | val_loss=0.2599 | val_acc=0.9247
  ↳ no‑improve (1/10)
[I 2025-06-20 21:44:55,596] Trial 2 finished with value: 0.9487179487179487 and parameters: {'lr': 0.00023687542089798446, 'batch_size': 16, 'optimizer': 'sgd', 'weight_decay': 2.613653475954567e-06, 'milestone1': 27, 'milestone2': 38, 'gamma': 0.2981291422222043, 'patience': 10, 'validation_freq': 5}. Best is trial 0 with value: 0.9551282051282052.

── Trial 3 ──
{
  "lr": 0.0017846498379351318,
  "batch_size": 32,
  "optimizer": "adam",
  "weight_decay": 0.0009936708149012956,
  "milestones": [
    16,
    43
  ],
  "gamma": 0.06753651882923399,
  "patience": 11,
  "val_freq": 7
}
→ Using 7 GPUs via DataParallel
Epoch  7 | train=0.4102 | val_loss=0.3777 | val_acc=0.8606
  ↳ improved
Epoch 14 | train=0.3540 | val_loss=0.5788 | val_acc=0.7083
  ↳ no‑improve (1/11)

                                                                                      

Best trial: 0. Best value: 0.955128:  15%|█▌        | 3/20 [46:19<3:40:08, 776.99s/it]
Best trial: 0. Best value: 0.955128:  15%|█▌        | 3/20 [46:19<3:40:08, 776.99s/it]
Best trial: 0. Best value: 0.955128:  20%|██        | 4/20 [46:19<3:09:17, 709.84s/it][I 2025-06-20 21:55:02,510] Trial 3 finished with value: 0.9086538461538461 and parameters: {'lr': 0.0017846498379351318, 'batch_size': 32, 'optimizer': 'adam', 'weight_decay': 0.0009936708149012956, 'milestone1': 16, 'milestone2': 43, 'gamma': 0.06753651882923399, 'patience': 11, 'validation_freq': 7}. Best is trial 0 with value: 0.9551282051282052.

── Trial 4 ──
{
  "lr": 0.0003614361421424066,
  "batch_size": 64,
  "optimizer": "adam",
  "weight_decay": 0.0002214243657001469,
  "milestones": [
    19,
    30
  ],
  "gamma": 0.1059121763845181,
  "patience": 12,
  "val_freq": 3
}
→ Using 7 GPUs via DataParallel
Epoch  3 | train=0.2275 | val_loss=0.3961 | val_acc=0.8942
  ↳ improved
Epoch  6 | train=0.1672 | val_loss=0.6995 | val_acc=0.8638
  ↳ no‑improve (1/12)
Epoch  9 | train=0.1575 | val_loss=0.1486 | val_acc=0.9423
  ↳ improved
Epoch 12 | train=0.1452 | val_loss=0.1525 | val_acc=0.9375
  ↳ no‑improve (1/12)
Epoch 15 | train=0.1526 | val_loss=0.1581 | val_acc=0.9455
  ↳ improved
Epoch 18 | train=0.1326 | val_loss=0.2235 | val_acc=0.9215
  ↳ no‑improve (1/12)

                                                                                      

Best trial: 0. Best value: 0.955128:  20%|██        | 4/20 [50:39<3:09:17, 709.84s/it]
Best trial: 0. Best value: 0.955128:  20%|██        | 4/20 [50:39<3:09:17, 709.84s/it]
Best trial: 0. Best value: 0.955128:  25%|██▌       | 5/20 [50:39<2:16:52, 547.48s/it][I 2025-06-20 21:59:22,090] Trial 4 finished with value: 0.9455128205128205 and parameters: {'lr': 0.0003614361421424066, 'batch_size': 64, 'optimizer': 'adam', 'weight_decay': 0.0002214243657001469, 'milestone1': 19, 'milestone2': 30, 'gamma': 0.1059121763845181, 'patience': 12, 'validation_freq': 3}. Best is trial 0 with value: 0.9551282051282052.

── Trial 5 ──
{
  "lr": 0.0002552217375761642,
  "batch_size": 32,
  "optimizer": "sgd",
  "weight_decay": 0.0007856351339934304,
  "milestones": [
    30,
    37
  ],
  "gamma": 0.1620331272582905,
  "patience": 6,
  "val_freq": 5
}
→ Using 7 GPUs via DataParallel
Epoch  5 | train=0.2999 | val_loss=0.2183 | val_acc=0.9247
  ↳ improved

                                                                                      

Best trial: 0. Best value: 0.955128:  25%|██▌       | 5/20 [53:40<2:16:52, 547.48s/it]
Best trial: 0. Best value: 0.955128:  25%|██▌       | 5/20 [53:40<2:16:52, 547.48s/it]
Best trial: 0. Best value: 0.955128:  30%|███       | 6/20 [53:40<1:38:40, 422.92s/it]Epoch 10 | train=0.2470 | val_loss=0.2145 | val_acc=0.9327
  ↳ improved
[I 2025-06-20 22:02:23,220] Trial 5 pruned. 

── Trial 6 ──
{
  "lr": 0.005196726617788022,
  "batch_size": 32,
  "optimizer": "adam",
  "weight_decay": 0.00043709061391159843,
  "milestones": [
    19,
    26
  ],
  "gamma": 0.22772523976683084,
  "patience": 7,
  "val_freq": 6
}
→ Using 7 GPUs via DataParallel
Epoch  6 | train=0.4640 | val_loss=0.6147 | val_acc=0.6282
  ↳ improved
                                                                                      Best trial: 0. Best value: 0.955128:  30%|███       | 6/20 [57:15<1:38:40, 422.92s/it]Best trial: 0. Best value: 0.955128:  30%|███       | 6/20 [57:15<1:38:40, 422.92s/it]Best trial: 0. Best value: 0.955128:  35%|███▌      | 7/20 [57:15<1:16:53, 354.91s/it]Epoch 12 | train=0.4350 | val_loss=0.6921 | val_acc=0.5897
  ↳ no‑improve (1/7)
[I 2025-06-20 22:05:58,125] Trial 6 pruned. 

── Trial 7 ──
{
  "lr": 0.0010517965092889177,
  "batch_size": 16,
  "optimizer": "sgd",
  "weight_decay": 1.688391734084175e-05,
  "milestones": [
    15,
    40
  ],
  "gamma": 0.1539412763508059,
  "patience": 10,
  "val_freq": 4
}
→ Using 7 GPUs via DataParallel
Epoch  4 | train=0.3584 | val_loss=0.1767 | val_acc=0.9439
  ↳ improved
Epoch  8 | train=0.2853 | val_loss=0.1963 | val_acc=0.9423
  ↳ no‑improve (1/10)
Epoch 12 | train=0.2519 | val_loss=0.2295 | val_acc=0.9151
  ↳ no‑improve (2/10)
Epoch 16 | train=0.1655 | val_loss=0.2554 | val_acc=0.9071
  ↳ no‑improve (3/10)
                                                                                      Best trial: 0. Best value: 0.955128:  35%|███▌      | 7/20 [1:07:18<1:16:53, 354.91s/it]Best trial: 0. Best value: 0.955128:  35%|███▌      | 7/20 [1:07:18<1:16:53, 354.91s/it]Best trial: 0. Best value: 0.955128:  40%|████      | 8/20 [1:07:18<1:26:48, 434.06s/it]Epoch 20 | train=0.1496 | val_loss=0.3358 | val_acc=0.8830
  ↳ no‑improve (4/10)
[I 2025-06-20 22:16:01,641] Trial 7 finished with value: 0.9439102564102564 and parameters: {'lr': 0.0010517965092889177, 'batch_size': 16, 'optimizer': 'sgd', 'weight_decay': 1.688391734084175e-05, 'milestone1': 15, 'milestone2': 40, 'gamma': 0.1539412763508059, 'patience': 10, 'validation_freq': 4}. Best is trial 0 with value: 0.9551282051282052.

── Trial 8 ──
{
  "lr": 0.006941957862974476,
  "batch_size": 32,
  "optimizer": "sgd",
  "weight_decay": 1.1428480571241946e-06,
  "milestones": [
    24,
    45
  ],
  "gamma": 0.2147105338160641,
  "patience": 5,
  "val_freq": 7
}
→ Using 7 GPUs via DataParallel
Epoch  7 | train=0.2389 | val_loss=0.4070 | val_acc=0.8478
  ↳ improved
Epoch 14 | train=0.1709 | val_loss=0.2375 | val_acc=0.9151
  ↳ improved
                                                                                        Best trial: 0. Best value: 0.955128:  40%|████      | 8/20 [1:13:15<1:26:48, 434.06s/it]Best trial: 0. Best value: 0.955128:  40%|████      | 8/20 [1:13:15<1:26:48, 434.06s/it]Best trial: 0. Best value: 0.955128:  45%|████▌     | 9/20 [1:13:15<1:15:09, 409.96s/it][I 2025-06-20 22:21:58,606] Trial 8 finished with value: 0.9326923076923077 and parameters: {'lr': 0.006941957862974476, 'batch_size': 32, 'optimizer': 'sgd', 'weight_decay': 1.1428480571241946e-06, 'milestone1': 24, 'milestone2': 45, 'gamma': 0.2147105338160641, 'patience': 5, 'validation_freq': 7}. Best is trial 0 with value: 0.9551282051282052.

── Trial 9 ──
{
  "lr": 0.0068188151679611075,
  "batch_size": 16,
  "optimizer": "adam",
  "weight_decay": 2.7217789733276296e-05,
  "milestones": [
    20,
    39
  ],
  "gamma": 0.2830116919417776,
  "patience": 15,
  "val_freq": 8
}
→ Using 7 GPUs via DataParallel
Epoch  8 | train=0.4167 | val_loss=0.5546 | val_acc=0.7179
  ↳ improved
                                                                                        Best trial: 0. Best value: 0.955128:  45%|████▌     | 9/20 [1:21:18<1:15:09, 409.96s/it]Best trial: 0. Best value: 0.955128:  45%|████▌     | 9/20 [1:21:18<1:15:09, 409.96s/it]Best trial: 0. Best value: 0.955128:  50%|█████     | 10/20 [1:21:18<1:12:05, 432.54s/it]Epoch 16 | train=0.3479 | val_loss=0.4043 | val_acc=0.8269
  ↳ improved
[I 2025-06-20 22:30:01,726] Trial 9 pruned. 

── Trial 10 ──
{
  "lr": 0.0029803895916735534,
  "batch_size": 64,
  "optimizer": "sgd",
  "weight_decay": 0.00710711298119914,
  "milestones": [
    35,
    42
  ],
  "gamma": 0.2585460917813032,
  "patience": 14,
  "val_freq": 6
}
→ Using 7 GPUs via DataParallel
Epoch  6 | train=0.1895 | val_loss=0.2707 | val_acc=0.9151
  ↳ improved
Epoch 12 | train=0.1543 | val_loss=0.1677 | val_acc=0.9407
  ↳ improved
Epoch 18 | train=0.1373 | val_loss=0.8478 | val_acc=0.8141
  ↳ no‑improve (1/14)
                                                                                         Best trial: 0. Best value: 0.955128:  50%|█████     | 10/20 [1:24:47<1:12:05, 432.54s/it]Best trial: 0. Best value: 0.955128:  50%|█████     | 10/20 [1:24:47<1:12:05, 432.54s/it]Best trial: 0. Best value: 0.955128:  55%|█████▌    | 11/20 [1:24:47<54:36, 364.09s/it]  [I 2025-06-20 22:33:30,618] Trial 10 finished with value: 0.9407051282051282 and parameters: {'lr': 0.0029803895916735534, 'batch_size': 64, 'optimizer': 'sgd', 'weight_decay': 0.00710711298119914, 'milestone1': 35, 'milestone2': 42, 'gamma': 0.2585460917813032, 'patience': 14, 'validation_freq': 6}. Best is trial 0 with value: 0.9551282051282052.

── Trial 11 ──
{
  "lr": 0.00011568517739005604,
  "batch_size": 64,
  "optimizer": "sgd",
  "weight_decay": 1.3892077571330666e-06,
  "milestones": [
    29,
    37
  ],
  "gamma": 0.29495459616797315,
  "patience": 13,
  "val_freq": 5
}
→ Using 7 GPUs via DataParallel
Epoch  5 | train=0.3310 | val_loss=0.3564 | val_acc=0.8285
  ↳ improved
                                                                                       Best trial: 0. Best value: 0.955128:  55%|█████▌    | 11/20 [1:26:33<54:36, 364.09s/it]Best trial: 0. Best value: 0.955128:  55%|█████▌    | 11/20 [1:26:33<54:36, 364.09s/it]Best trial: 0. Best value: 0.955128:  60%|██████    | 12/20 [1:26:33<38:04, 285.55s/it]Epoch 10 | train=0.2795 | val_loss=0.2844 | val_acc=0.8734
  ↳ improved
[I 2025-06-20 22:35:16,528] Trial 11 pruned. 

── Trial 12 ──
{
  "lr": 0.0006753909747605693,
  "batch_size": 64,
  "optimizer": "sgd",
  "weight_decay": 0.008003638620606093,
  "milestones": [
    29,
    37
  ],
  "gamma": 0.29416633787692115,
  "patience": 8,
  "val_freq": 5
}
→ Using 7 GPUs via DataParallel
Epoch  5 | train=0.2437 | val_loss=0.2754 | val_acc=0.9006
  ↳ improved
                                                                                       Best trial: 0. Best value: 0.955128:  60%|██████    | 12/20 [1:28:22<38:04, 285.55s/it]Best trial: 0. Best value: 0.955128:  60%|██████    | 12/20 [1:28:22<38:04, 285.55s/it]Best trial: 0. Best value: 0.955128:  65%|██████▌   | 13/20 [1:28:22<27:04, 232.08s/it]Epoch 10 | train=0.1953 | val_loss=0.3234 | val_acc=0.8942
  ↳ no‑improve (1/8)
[I 2025-06-20 22:37:05,551] Trial 12 pruned. 

── Trial 13 ──
{
  "lr": 0.00012559236903425392,
  "batch_size": 16,
  "optimizer": "sgd",
  "weight_decay": 5.6087921731318355e-06,
  "milestones": [
    32,
    39
  ],
  "gamma": 0.1952433580915922,
  "patience": 11,
  "val_freq": 7
}
→ Using 7 GPUs via DataParallel
Epoch  7 | train=0.3488 | val_loss=0.2150 | val_acc=0.9295
  ↳ improved
Epoch 14 | train=0.3190 | val_loss=0.2262 | val_acc=0.9215
  ↳ no‑improve (1/11)
                                                                                       Best trial: 0. Best value: 0.955128:  65%|██████▌   | 13/20 [1:38:23<27:04, 232.08s/it]Best trial: 0. Best value: 0.955128:  65%|██████▌   | 13/20 [1:38:23<27:04, 232.08s/it]Best trial: 0. Best value: 0.955128:  70%|███████   | 14/20 [1:38:23<34:20, 343.45s/it][I 2025-06-20 22:47:06,371] Trial 13 finished with value: 0.9375 and parameters: {'lr': 0.00012559236903425392, 'batch_size': 16, 'optimizer': 'sgd', 'weight_decay': 5.6087921731318355e-06, 'milestone1': 32, 'milestone2': 39, 'gamma': 0.1952433580915922, 'patience': 11, 'validation_freq': 7}. Best is trial 0 with value: 0.9551282051282052.

── Trial 14 ──
{
  "lr": 0.0006921171258915674,
  "batch_size": 64,
  "optimizer": "sgd",
  "weight_decay": 0.0018670617639716908,
  "milestones": [
    26,
    34
  ],
  "gamma": 0.26512266769238513,
  "patience": 9,
  "val_freq": 4
}
→ Using 7 GPUs via DataParallel
Epoch  4 | train=0.2435 | val_loss=0.2923 | val_acc=0.8894
  ↳ improved
Epoch  8 | train=0.2101 | val_loss=0.1872 | val_acc=0.9327
  ↳ improved
                                                                                       Best trial: 0. Best value: 0.955128:  70%|███████   | 14/20 [1:40:40<34:20, 343.45s/it]Best trial: 0. Best value: 0.955128:  70%|███████   | 14/20 [1:40:40<34:20, 343.45s/it]Best trial: 0. Best value: 0.955128:  75%|███████▌  | 15/20 [1:40:40<23:26, 281.23s/it]Epoch 12 | train=0.1920 | val_loss=0.2616 | val_acc=0.9231
  ↳ no‑improve (1/9)
[I 2025-06-20 22:49:23,405] Trial 14 pruned. 

── Trial 15 ──
{
  "lr": 0.003045937459084174,
  "batch_size": 16,
  "optimizer": "sgd",
  "weight_decay": 8.181196932311436e-05,
  "milestones": [
    26,
    35
  ],
  "gamma": 0.2537669420447867,
  "patience": 12,
  "val_freq": 6
}
→ Using 7 GPUs via DataParallel
Epoch  6 | train=0.2570 | val_loss=0.1833 | val_acc=0.9327
  ↳ improved
                                                                                       Best trial: 0. Best value: 0.955128:  75%|███████▌  | 15/20 [1:46:44<23:26, 281.23s/it]Best trial: 0. Best value: 0.955128:  75%|███████▌  | 15/20 [1:46:44<23:26, 281.23s/it]Best trial: 0. Best value: 0.955128:  80%|████████  | 16/20 [1:46:44<20:24, 306.24s/it]Epoch 12 | train=0.1789 | val_loss=0.5179 | val_acc=0.8333
  ↳ no‑improve (1/12)
[I 2025-06-20 22:55:27,709] Trial 15 pruned. 

── Trial 16 ──
{
  "lr": 0.0014563822320437857,
  "batch_size": 16,
  "optimizer": "sgd",
  "weight_decay": 3.8264670813801256e-06,
  "milestones": [
    33,
    41
  ],
  "gamma": 0.14055950330442563,
  "patience": 13,
  "val_freq": 3
}
→ Using 7 GPUs via DataParallel
Epoch  3 | train=0.3542 | val_loss=0.1861 | val_acc=0.9503
  ↳ improved
Epoch  6 | train=0.3122 | val_loss=0.1718 | val_acc=0.9439
  ↳ no‑improve (1/13)
Epoch  9 | train=0.2681 | val_loss=0.3528 | val_acc=0.8798
  ↳ no‑improve (2/13)
Epoch 12 | train=0.2030 | val_loss=0.2302 | val_acc=0.9199
  ↳ no‑improve (3/13)
Epoch 15 | train=0.1714 | val_loss=0.2194 | val_acc=0.9359
  ↳ no‑improve (4/13)
Epoch 18 | train=0.1554 | val_loss=0.2141 | val_acc=0.9407
  ↳ no‑improve (5/13)
                                                                                       Best trial: 0. Best value: 0.955128:  80%|████████  | 16/20 [1:57:02<20:24, 306.24s/it]Best trial: 0. Best value: 0.955128:  80%|████████  | 16/20 [1:57:02<20:24, 306.24s/it]Best trial: 0. Best value: 0.955128:  85%|████████▌ | 17/20 [1:57:02<19:59, 399.84s/it][I 2025-06-20 23:05:45,215] Trial 16 finished with value: 0.9503205128205128 and parameters: {'lr': 0.0014563822320437857, 'batch_size': 16, 'optimizer': 'sgd', 'weight_decay': 3.8264670813801256e-06, 'milestone1': 33, 'milestone2': 41, 'gamma': 0.14055950330442563, 'patience': 13, 'validation_freq': 3}. Best is trial 0 with value: 0.9551282051282052.

── Trial 17 ──
{
  "lr": 0.0033610789666792345,
  "batch_size": 64,
  "optimizer": "sgd",
  "weight_decay": 9.441368301589932e-05,
  "milestones": [
    35,
    43
  ],
  "gamma": 0.10843570342217632,
  "patience": 15,
  "val_freq": 3
}
→ Using 7 GPUs via DataParallel
Epoch  3 | train=0.2222 | val_loss=0.2026 | val_acc=0.9487
  ↳ improved
Epoch  6 | train=0.1856 | val_loss=0.3637 | val_acc=0.8814
  ↳ no‑improve (1/15)
Epoch  9 | train=0.1724 | val_loss=0.1700 | val_acc=0.9311
  ↳ no‑improve (2/15)
Epoch 12 | train=0.1526 | val_loss=0.3235 | val_acc=0.9167
  ↳ no‑improve (3/15)
Epoch 15 | train=0.1282 | val_loss=0.2080 | val_acc=0.9343
  ↳ no‑improve (4/15)
Epoch 18 | train=0.1281 | val_loss=0.3711 | val_acc=0.8942
  ↳ no‑improve (5/15)
                                                                                       Best trial: 0. Best value: 0.955128:  85%|████████▌ | 17/20 [2:00:35<19:59, 399.84s/it]Best trial: 0. Best value: 0.955128:  85%|████████▌ | 17/20 [2:00:35<19:59, 399.84s/it]Best trial: 0. Best value: 0.955128:  90%|█████████ | 18/20 [2:00:35<11:27, 343.84s/it][I 2025-06-20 23:09:18,688] Trial 17 finished with value: 0.9487179487179487 and parameters: {'lr': 0.0033610789666792345, 'batch_size': 64, 'optimizer': 'sgd', 'weight_decay': 9.441368301589932e-05, 'milestone1': 35, 'milestone2': 43, 'gamma': 0.10843570342217632, 'patience': 15, 'validation_freq': 3}. Best is trial 0 with value: 0.9551282051282052.

── Trial 18 ──
{
  "lr": 0.00963202849897143,
  "batch_size": 64,
  "optimizer": "sgd",
  "weight_decay": 7.208531661224438e-06,
  "milestones": [
    32,
    41
  ],
  "gamma": 0.13343275298363153,
  "patience": 13,
  "val_freq": 8
}
→ Using 7 GPUs via DataParallel
Epoch  8 | train=0.1804 | val_loss=0.3193 | val_acc=0.9295
  ↳ improved
Epoch 16 | train=0.1305 | val_loss=0.1710 | val_acc=0.9391
  ↳ improved
                                                                                       Best trial: 0. Best value: 0.955128:  90%|█████████ | 18/20 [2:04:10<11:27, 343.84s/it]Best trial: 0. Best value: 0.955128:  90%|█████████ | 18/20 [2:04:10<11:27, 343.84s/it]Best trial: 0. Best value: 0.955128:  95%|█████████▌| 19/20 [2:04:10<05:04, 304.94s/it][I 2025-06-20 23:12:53,005] Trial 18 finished with value: 0.9391025641025641 and parameters: {'lr': 0.00963202849897143, 'batch_size': 64, 'optimizer': 'sgd', 'weight_decay': 7.208531661224438e-06, 'milestone1': 32, 'milestone2': 41, 'gamma': 0.13343275298363153, 'patience': 13, 'validation_freq': 8}. Best is trial 0 with value: 0.9551282051282052.

── Trial 19 ──
{
  "lr": 0.0012805510459555818,
  "batch_size": 16,
  "optimizer": "sgd",
  "weight_decay": 0.0034177461039604264,
  "milestones": [
    32,
    41
  ],
  "gamma": 0.18878694542993146,
  "patience": 13,
  "val_freq": 3
}
→ Using 7 GPUs via DataParallel
Epoch  3 | train=0.3373 | val_loss=0.2436 | val_acc=0.9215
  ↳ improved
Epoch  6 | train=0.2945 | val_loss=0.2505 | val_acc=0.9199
  ↳ no‑improve (1/13)
Epoch  9 | train=0.2603 | val_loss=0.1980 | val_acc=0.9311
  ↳ improved
                                                                                       Best trial: 0. Best value: 0.955128:  95%|█████████▌| 19/20 [2:10:24<05:04, 304.94s/it]Best trial: 0. Best value: 0.955128:  95%|█████████▌| 19/20 [2:10:24<05:04, 304.94s/it]Best trial: 0. Best value: 0.955128: 100%|██████████| 20/20 [2:10:24<00:00, 325.67s/it]Best trial: 0. Best value: 0.955128: 100%|██████████| 20/20 [2:10:24<00:00, 391.21s/it]
Epoch 12 | train=0.2143 | val_loss=0.1893 | val_acc=0.9327
  ↳ improved
[I 2025-06-20 23:19:06,990] Trial 19 pruned. 

============================================================
HPO finished » best_trial=0 | best_acc=0.9551
  lr: 0.008244162602397142
  batch_size: 64
  optimizer: sgd
  weight_decay: 0.002712782161696706
  milestone1: 30
  milestone2: 38
  gamma: 0.2740513446648188
  patience: 12
  validation_freq: 6

Retraining with best parameters:
{
  "lr": 0.008244162602397142,
  "batch_size": 64,
  "optimizer": "sgd",
  "weight_decay": 0.002712782161696706,
  "milestone1": 30,
  "milestone2": 38,
  "gamma": 0.2740513446648188,
  "patience": 12,
  "validation_freq": 6
}
Using 7 GPUs via DataParallel

Starting full training (max 100 epochs)…
------------------------------------------------------------
Epoch   1 | train_loss=0.3729 | val_loss=0.6102 | val_acc=0.8397 | lr=0.008244
          → New best model saved (0.8397)
Epoch   2 | train_loss=0.2728 | val_loss=0.2162 | val_acc=0.9439 | lr=0.008244
          → New best model saved (0.9439)
Epoch   3 | train_loss=0.2606 | val_loss=0.3592 | val_acc=0.8974 | lr=0.008244
Epoch   4 | train_loss=0.2382 | val_loss=0.1241 | val_acc=0.9535 | lr=0.008244
          → New best model saved (0.9535)
Epoch   5 | train_loss=0.2116 | val_loss=0.3335 | val_acc=0.9022 | lr=0.008244
Epoch   6 | train_loss=0.1877 | val_loss=0.1428 | val_acc=0.9535 | lr=0.008244
Epoch   7 | train_loss=0.1858 | val_loss=0.3272 | val_acc=0.8862 | lr=0.008244
Epoch   8 | train_loss=0.1638 | val_loss=0.4270 | val_acc=0.8686 | lr=0.008244
Epoch   9 | train_loss=0.1532 | val_loss=0.1849 | val_acc=0.9407 | lr=0.008244
Epoch  10 | train_loss=0.1586 | val_loss=0.1730 | val_acc=0.9471 | lr=0.008244
Epoch  11 | train_loss=0.1611 | val_loss=0.5145 | val_acc=0.8205 | lr=0.008244
Epoch  12 | train_loss=0.1444 | val_loss=0.2756 | val_acc=0.8990 | lr=0.008244
Epoch  13 | train_loss=0.1675 | val_loss=0.1680 | val_acc=0.9359 | lr=0.008244
Epoch  14 | train_loss=0.1506 | val_loss=0.2278 | val_acc=0.9054 | lr=0.008244
Epoch  15 | train_loss=0.1544 | val_loss=0.1865 | val_acc=0.9423 | lr=0.008244
Epoch  16 | train_loss=0.1512 | val_loss=0.1223 | val_acc=0.9599 | lr=0.008244
          → New best model saved (0.9599)
Epoch  17 | train_loss=0.1402 | val_loss=0.1991 | val_acc=0.9455 | lr=0.008244
Epoch  18 | train_loss=0.1304 | val_loss=0.2894 | val_acc=0.9247 | lr=0.008244
Epoch  19 | train_loss=0.1400 | val_loss=0.1478 | val_acc=0.9423 | lr=0.008244
Epoch  20 | train_loss=0.1437 | val_loss=0.2818 | val_acc=0.9183 | lr=0.008244
Epoch  21 | train_loss=0.1515 | val_loss=0.1230 | val_acc=0.9455 | lr=0.008244
Epoch  22 | train_loss=0.1290 | val_loss=0.2532 | val_acc=0.9279 | lr=0.008244
Epoch  23 | train_loss=0.1272 | val_loss=0.1955 | val_acc=0.9343 | lr=0.008244
Epoch  24 | train_loss=0.1158 | val_loss=0.1694 | val_acc=0.9311 | lr=0.008244
Epoch  25 | train_loss=0.1163 | val_loss=0.1587 | val_acc=0.9423 | lr=0.008244
Epoch  26 | train_loss=0.1250 | val_loss=0.3620 | val_acc=0.8766 | lr=0.008244
Epoch  27 | train_loss=0.1394 | val_loss=0.2555 | val_acc=0.9135 | lr=0.008244
Epoch  28 | train_loss=0.1314 | val_loss=0.2808 | val_acc=0.9119 | lr=0.008244
Epoch  29 | train_loss=0.1195 | val_loss=0.1906 | val_acc=0.9343 | lr=0.008244
Epoch  30 | train_loss=0.1094 | val_loss=0.1475 | val_acc=0.9423 | lr=0.002259
Epoch  31 | train_loss=0.1087 | val_loss=0.2290 | val_acc=0.9263 | lr=0.002259
Epoch  32 | train_loss=0.0885 | val_loss=0.1476 | val_acc=0.9519 | lr=0.002259
Epoch  33 | train_loss=0.0940 | val_loss=0.2011 | val_acc=0.9311 | lr=0.002259
Epoch  34 | train_loss=0.0782 | val_loss=0.2062 | val_acc=0.9343 | lr=0.002259
Epoch  35 | train_loss=0.0845 | val_loss=0.1894 | val_acc=0.9343 | lr=0.002259
Epoch  36 | train_loss=0.0843 | val_loss=0.3145 | val_acc=0.9103 | lr=0.002259
Epoch  37 | train_loss=0.0905 | val_loss=0.2272 | val_acc=0.9295 | lr=0.002259
Epoch  38 | train_loss=0.0764 | val_loss=0.2843 | val_acc=0.9038 | lr=0.000619
Epoch  39 | train_loss=0.0796 | val_loss=0.2256 | val_acc=0.9215 | lr=0.000619
Epoch  40 | train_loss=0.0709 | val_loss=0.2625 | val_acc=0.9167 | lr=0.000619
Epoch  41 | train_loss=0.0650 | val_loss=0.2032 | val_acc=0.9295 | lr=0.000619
Epoch  42 | train_loss=0.0627 | val_loss=0.2420 | val_acc=0.9231 | lr=0.000619
Epoch  43 | train_loss=0.0688 | val_loss=0.2489 | val_acc=0.9215 | lr=0.000619
Epoch  44 | train_loss=0.0617 | val_loss=0.1683 | val_acc=0.9391 | lr=0.000619
Epoch  45 | train_loss=0.0566 | val_loss=0.2210 | val_acc=0.9295 | lr=0.000619
Epoch  46 | train_loss=0.0603 | val_loss=0.1558 | val_acc=0.9423 | lr=0.000619
Epoch  47 | train_loss=0.0611 | val_loss=0.1735 | val_acc=0.9343 | lr=0.000619
Epoch  48 | train_loss=0.0616 | val_loss=0.2672 | val_acc=0.9119 | lr=0.000619
Epoch  49 | train_loss=0.0538 | val_loss=0.2500 | val_acc=0.9167 | lr=0.000619
Epoch  50 | train_loss=0.0647 | val_loss=0.1850 | val_acc=0.9343 | lr=0.000619
Epoch  51 | train_loss=0.0625 | val_loss=0.2161 | val_acc=0.9311 | lr=0.000619
Epoch  52 | train_loss=0.0582 | val_loss=0.2667 | val_acc=0.9135 | lr=0.000619
Epoch  53 | train_loss=0.0561 | val_loss=0.2586 | val_acc=0.9199 | lr=0.000619
Epoch  54 | train_loss=0.0578 | val_loss=0.2422 | val_acc=0.9311 | lr=0.000619
Epoch  55 | train_loss=0.0512 | val_loss=0.2779 | val_acc=0.9119 | lr=0.000619
Epoch  56 | train_loss=0.0661 | val_loss=0.2673 | val_acc=0.9215 | lr=0.000619
Epoch  57 | train_loss=0.0557 | val_loss=0.3376 | val_acc=0.9006 | lr=0.000619
Epoch  58 | train_loss=0.0571 | val_loss=0.2391 | val_acc=0.9279 | lr=0.000619
Epoch  59 | train_loss=0.0556 | val_loss=0.1734 | val_acc=0.9375 | lr=0.000619
Epoch  60 | train_loss=0.0552 | val_loss=0.1893 | val_acc=0.9327 | lr=0.000619
Epoch  61 | train_loss=0.0570 | val_loss=0.2057 | val_acc=0.9295 | lr=0.000619
Epoch  62 | train_loss=0.0528 | val_loss=0.2525 | val_acc=0.9215 | lr=0.000619
Epoch  63 | train_loss=0.0527 | val_loss=0.2810 | val_acc=0.9167 | lr=0.000619
Epoch  64 | train_loss=0.0612 | val_loss=0.2034 | val_acc=0.9359 | lr=0.000619
Epoch  65 | train_loss=0.0614 | val_loss=0.2076 | val_acc=0.9263 | lr=0.000619
Epoch  66 | train_loss=0.0496 | val_loss=0.3216 | val_acc=0.9135 | lr=0.000619
Epoch  67 | train_loss=0.0552 | val_loss=0.2359 | val_acc=0.9215 | lr=0.000619
Epoch  68 | train_loss=0.0550 | val_loss=0.2219 | val_acc=0.9279 | lr=0.000619
Epoch  69 | train_loss=0.0521 | val_loss=0.1903 | val_acc=0.9423 | lr=0.000619
Epoch  70 | train_loss=0.0515 | val_loss=0.1741 | val_acc=0.9407 | lr=0.000619
Epoch  71 | train_loss=0.0502 | val_loss=0.1813 | val_acc=0.9391 | lr=0.000619
Epoch  72 | train_loss=0.0521 | val_loss=0.2029 | val_acc=0.9295 | lr=0.000619
Epoch  73 | train_loss=0.0468 | val_loss=0.1597 | val_acc=0.9487 | lr=0.000619
Epoch  74 | train_loss=0.0489 | val_loss=0.1917 | val_acc=0.9295 | lr=0.000619
Epoch  75 | train_loss=0.0585 | val_loss=0.1984 | val_acc=0.9391 | lr=0.000619
Epoch  76 | train_loss=0.0574 | val_loss=0.2755 | val_acc=0.9119 | lr=0.000619
Epoch  77 | train_loss=0.0516 | val_loss=0.1797 | val_acc=0.9407 | lr=0.000619
Epoch  78 | train_loss=0.0576 | val_loss=0.1719 | val_acc=0.9407 | lr=0.000619
Epoch  79 | train_loss=0.0479 | val_loss=0.2538 | val_acc=0.9183 | lr=0.000619
Epoch  80 | train_loss=0.0490 | val_loss=0.2498 | val_acc=0.9135 | lr=0.000619
Epoch  81 | train_loss=0.0470 | val_loss=0.2923 | val_acc=0.9135 | lr=0.000619
Epoch  82 | train_loss=0.0489 | val_loss=0.3682 | val_acc=0.8942 | lr=0.000619
Epoch  83 | train_loss=0.0562 | val_loss=0.2494 | val_acc=0.9151 | lr=0.000619
Epoch  84 | train_loss=0.0507 | val_loss=0.1490 | val_acc=0.9535 | lr=0.000619
Epoch  85 | train_loss=0.0429 | val_loss=0.2513 | val_acc=0.9247 | lr=0.000619
Epoch  86 | train_loss=0.0550 | val_loss=0.2024 | val_acc=0.9423 | lr=0.000619
Epoch  87 | train_loss=0.0527 | val_loss=0.2040 | val_acc=0.9343 | lr=0.000619
Epoch  88 | train_loss=0.0422 | val_loss=0.2225 | val_acc=0.9327 | lr=0.000619

Early‑stopping after 72 no‑improve epochs → best_acc=0.9599
------------------------------------------------------------
Training finished • best_val_acc=0.9599
Final accuracy=0.9599 | final loss=0.1223
Training curves saved as training_curves.png
